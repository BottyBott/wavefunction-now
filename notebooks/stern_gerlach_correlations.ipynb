{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109677de",
   "metadata": {},
   "source": [
    "# Sequential Spin Constraints (Stern–Gerlach)\n",
    "\n",
    "By simulating back-to-back Stern–Gerlach measurements, we show how contextual constraints govern which correlations survive. The notebook highlights that “collapse” is simply the system reorganising under a new constraint in the present. It illustrates the systemic thesis: the measured spin, magnets, and detectors act as one whole whose lawful behaviour is validated through current correlations, not inferred histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da00a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from wavefunction_now.measurement import chi_squared_gof, ks_goodness_of_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5836a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(123)\n",
    "\n",
    "ket_up_z = np.array([1.0, 0.0], dtype=complex)\n",
    "ket_down_z = np.array([0.0, 1.0], dtype=complex)\n",
    "ket_plus_x = (ket_up_z + ket_down_z) / np.sqrt(2)\n",
    "\n",
    "proj_up_z = np.outer(ket_up_z, ket_up_z.conj())\n",
    "proj_down_z = np.outer(ket_down_z, ket_down_z.conj())\n",
    "proj_plus_x = 0.5 * np.array([[1, 1], [1, 1]], dtype=complex)\n",
    "proj_minus_x = 0.5 * np.array([[1, -1], [-1, 1]], dtype=complex)\n",
    "\n",
    "projectors_z = [proj_up_z, proj_down_z]\n",
    "projectors_x = [proj_plus_x, proj_minus_x]\n",
    "\n",
    "def projective_measure(state, projectors):\n",
    "    probs = np.array([np.real(state.conj().T @ P @ state) for P in projectors])\n",
    "    probs = np.clip(probs, 0.0, 1.0)\n",
    "    probs = probs / probs.sum()\n",
    "    outcome = rng.choice(len(projectors), p=probs)\n",
    "    post = projectors[outcome] @ state\n",
    "    post_norm = np.linalg.norm(post)\n",
    "    if post_norm == 0:\n",
    "        raise RuntimeError('Projection annihilated the state.')\n",
    "    return outcome, post / post_norm\n",
    "\n",
    "def run_sequence(num_events, second_axis):\n",
    "    if second_axis == 'z':\n",
    "        projectors_second = projectors_z\n",
    "        expected = np.array([0.5, 0.5])\n",
    "        events = np.zeros(num_events, dtype=int)\n",
    "        counts = np.zeros(2, dtype=int)\n",
    "    elif second_axis == 'x':\n",
    "        projectors_second = projectors_x\n",
    "        expected = np.full(4, 0.25)\n",
    "        events = np.zeros(num_events, dtype=int)\n",
    "        counts = np.zeros(4, dtype=int)\n",
    "    else:\n",
    "        raise ValueError('second_axis must be \"z\" or \"x\"')\n",
    "\n",
    "    for i in range(num_events):\n",
    "        state = ket_plus_x.copy()\n",
    "        first_outcome, state = projective_measure(state, projectors_z)\n",
    "        second_outcome, state = projective_measure(state, projectors_second)\n",
    "        if second_axis == 'z':\n",
    "            idx = first_outcome\n",
    "        else:\n",
    "            idx = first_outcome * 2 + second_outcome\n",
    "        counts[idx] += 1\n",
    "        events[i] = idx\n",
    "\n",
    "    return counts, events, expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5e557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z then Z (matching axis)\n",
      "Counts: [2525 2475]\n",
      "Chi-squared statistic: 0.500, p-value: 0.480\n",
      "KS statistic: 0.005, p-value: 0.776\n"
     ]
    }
   ],
   "source": [
    "counts_same, events_same, expected_same = run_sequence(5000, 'z')\n",
    "chi2_same, p_same = chi_squared_gof(expected_same, counts_same)\n",
    "d_same, ks_p_same = ks_goodness_of_fit(expected_same, events_same)\n",
    "\n",
    "print('Z then Z (matching axis)')\n",
    "print('Counts:', counts_same)\n",
    "print(f'Chi-squared statistic: {chi2_same:.3f}, p-value: {p_same:.3f}')\n",
    "print(f'KS statistic: {d_same:.3f}, p-value: {ks_p_same:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0175258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Z then X (orthogonal axis)\n",
      "Counts: [1240 1242 1263 1255]\n",
      "Chi-squared statistic: 0.286, p-value: 0.963\n",
      "KS statistic: 0.004, p-value: 0.876\n"
     ]
    }
   ],
   "source": [
    "counts_cross, events_cross, expected_cross = run_sequence(5000, 'x')\n",
    "chi2_cross, p_cross = chi_squared_gof(expected_cross, counts_cross)\n",
    "d_cross, ks_p_cross = ks_goodness_of_fit(expected_cross, events_cross)\n",
    "\n",
    "print('\\nZ then X (orthogonal axis)')\n",
    "print('Counts:', counts_cross)\n",
    "print(f'Chi-squared statistic: {chi2_cross:.3f}, p-value: {p_cross:.3f}')\n",
    "print(f'KS statistic: {d_cross:.3f}, p-value: {ks_p_cross:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249df9d6",
   "metadata": {},
   "source": [
    "Sequential measurements along the same axis retain the initial outcome, whereas switching to an orthogonal axis restores a uniform distribution. Both behaviours fall naturally out of present-time projective updates and are captured by the statistical tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
